{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61580019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train columns: ['sl_no', 'gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s', 'degree_p', 'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p', 'status', 'salary']\n",
      "Test columns: ['sl_no', 'gender', 'salary']\n",
      "\n",
      "--- Train head ---\n",
      "   sl_no  gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p  \\\n",
      "0      1       0  67.00   Others  91.00   Others  Commerce     58.00   \n",
      "1      2       0  79.33  Central  78.33   Others   Science     77.48   \n",
      "2      3       0  65.00  Central  68.00  Central      Arts     64.00   \n",
      "3      4       0  56.00  Central  52.00  Central   Science     52.00   \n",
      "4      5       0  85.80  Central  73.60  Central  Commerce     73.30   \n",
      "\n",
      "    degree_t workex  etest_p specialisation  mba_p  status    salary  \n",
      "0   Sci&Tech     No     55.0         Mkt&HR  58.80       1  270000.0  \n",
      "1   Sci&Tech    Yes     86.5        Mkt&Fin  66.28       1  200000.0  \n",
      "2  Comm&Mgmt     No     75.0        Mkt&Fin  57.80       1  250000.0  \n",
      "3   Sci&Tech     No     66.0         Mkt&HR  59.43       0       NaN  \n",
      "4  Comm&Mgmt     No     96.8        Mkt&Fin  55.50       1  425000.0  \n",
      "Missing in train:\n",
      " sl_no              0\n",
      "gender             0\n",
      "ssc_p              0\n",
      "ssc_b              0\n",
      "hsc_p              0\n",
      "hsc_b              0\n",
      "hsc_s              0\n",
      "degree_p           0\n",
      "degree_t           0\n",
      "workex             0\n",
      "etest_p            0\n",
      "specialisation     0\n",
      "mba_p              0\n",
      "status             0\n",
      "salary            67\n",
      "dtype: int64\n",
      "\n",
      "--- Test head ---\n",
      "   sl_no  gender         salary\n",
      "0    123       1  236000.000000\n",
      "1    199       1  288655.405405\n",
      "2    138       0  225000.000000\n",
      "3    137       1  288655.405405\n",
      "4     76       1  288655.405405\n",
      "Missing in test:\n",
      " sl_no     0\n",
      "gender    0\n",
      "salary    0\n",
      "dtype: int64\n",
      "Categorical columns: ['ssc_b', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'specialisation']\n",
      "\n",
      "Tuning RandomForest...\n",
      "RF best params: {'max_depth': None, 'n_estimators': 100}\n",
      "Tuning SVM...\n",
      "SVM best params: {'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Validation metrics:\n",
      "Logistic {'acc': 0.8153846153846154, 'f1': 0.8666666666666667, 'roc': 0.9307359307359307}\n",
      "Tree {'acc': 0.8923076923076924, 'f1': 0.9230769230769231, 'roc': 0.8582251082251082}\n",
      "Forest {'acc': 0.8923076923076924, 'f1': 0.9263157894736842, 'roc': 0.9935064935064934}\n",
      "SVM {'acc': 0.8, 'f1': 0.8602150537634409, 'roc': 0.9231601731601732}\n",
      "KNN {'acc': 0.6923076923076923, 'f1': 0.7959183673469388, 'roc': 0.7364718614718615}\n",
      "Best model by F1: Forest\n",
      "Confusion matrix:\n",
      " [[14  7]\n",
      " [ 0 44]]\n",
      "Voting F1: 0.9565217391304348\n",
      "Submission written to submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 0. User settings: adjust these\n",
    "# ---------------------------------------------\n",
    "# Paths to your Kaggle files (Windows raw strings)\n",
    "train_path = r\"D:\\ninic\\train.csv\"\n",
    "test_path = r\"D:\\ninic\\test.csv\"\n",
    "# Name of the ID column and target column\n",
    "id_col = 'sl_no'\n",
    "target_col = 'status'  # actual target column name\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1. Load datasets\n",
    "# ---------------------------------------------\n",
    "print(\"Loading datasets...\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "print(f\"Train columns: {train_df.columns.tolist()}\")\n",
    "print(f\"Test columns: {test_df.columns.tolist()}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. Encode target variable\n",
    "# ---------------------------------------------\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_target = LabelEncoder()\n",
    "train_df[target_col] = le_target.fit_transform(train_df[target_col])  # e.g. 'Placed'->1, 'Not Placed'->0\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3. Quick sanity checks\n",
    "# ---------------------------------------------\n",
    "if target_col not in train_df.columns:\n",
    "    raise KeyError(f\"Target column '{target_col}' missing. Available: {train_df.columns.tolist()}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4. EDA (basic)\n",
    "# ---------------------------------------------\n",
    "print(\"\\n--- Train head ---\")\n",
    "print(train_df.head())\n",
    "print(\"Missing in train:\\n\", train_df.isnull().sum())\n",
    "print(\"\\n--- Test head ---\")\n",
    "print(test_df.head())\n",
    "print(\"Missing in test:\\n\", test_df.isnull().sum())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5. Combine for consistent encoding\n",
    "# ---------------------------------------------\n",
    "test_ids = test_df[id_col]\n",
    "all_df = pd.concat([train_df.drop(columns=[target_col]), test_df], axis=0)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6. Fill missing\n",
    "# ---------------------------------------------\n",
    "def fill_na(df):\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype in [np.float64, np.int64]:\n",
    "            df[c].fillna(df[c].median(), inplace=True)\n",
    "        else:\n",
    "            df[c].fillna(df[c].mode()[0], inplace=True)\n",
    "fill_na(all_df)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 7. Encode features\n",
    "# ---------------------------------------------\n",
    "cat_cols = all_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {cat_cols}\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "fe_le = LabelEncoder()\n",
    "onehot = [c for c in cat_cols if all_df[c].nunique() > 2]\n",
    "all_df = pd.get_dummies(all_df, columns=onehot, drop_first=True)\n",
    "for c in cat_cols:\n",
    "    if c not in onehot:\n",
    "        all_df[c] = fe_le.fit_transform(all_df[c])\n",
    "\n",
    "# Split back\n",
    "glen = len(train_df)\n",
    "X = all_df.iloc[:glen].drop(columns=[id_col])\n",
    "y = train_df[target_col]\n",
    "X_test = all_df.iloc[glen:].drop(columns=[id_col])\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 8. Train/validation split\n",
    "# ---------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 9. Scale for select models\n",
    "# ---------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_val_sc = scaler.transform(X_val)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 10. Define and tune models\n",
    "# ---------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "models = {\n",
    "    'Logistic': LogisticRegression(max_iter=200),\n",
    "    'Tree': DecisionTreeClassifier(),\n",
    "    'Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# RandomForest tuning\n",
    "print(\"\\nTuning RandomForest...\")\n",
    "rf_params = {'n_estimators': [50, 100], 'max_depth': [None, 5]}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), rf_params, cv=3)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "models['Forest'] = grid_rf.best_estimator_\n",
    "print(\"RF best params:\", grid_rf.best_params_)\n",
    "\n",
    "# SVM tuning on scaled data\n",
    "print(\"Tuning SVM...\")\n",
    "svm_params = {'C': [0.1, 1], 'kernel': ['linear', 'rbf']}\n",
    "grid_svm = GridSearchCV(SVC(probability=True), svm_params, cv=3)\n",
    "grid_svm.fit(X_train_sc, y_train)\n",
    "models['SVM'] = grid_svm.best_estimator_\n",
    "print(\"SVM best params:\", grid_svm.best_params_)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 11. Evaluation\n",
    "# ---------------------------------------------\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def evaluate(name, model, scaled=False):\n",
    "    Xtr, Xte = (X_train_sc, X_val_sc) if scaled else (X_train, X_val)\n",
    "    model.fit(Xtr, y_train)\n",
    "    preds = model.predict(Xte)\n",
    "    probs = model.predict_proba(Xte)[:,1]\n",
    "    return {\n",
    "        'acc': accuracy_score(y_val, preds),\n",
    "        'f1': f1_score(y_val, preds),\n",
    "        'roc': roc_auc_score(y_val, probs)\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "for n, m in models.items():\n",
    "    results[n] = evaluate(n, m, scaled=(n in ['Logistic', 'SVM', 'KNN']))\n",
    "print(\"\\nValidation metrics:\")\n",
    "for k, v in results.items(): print(k, v)\n",
    "\n",
    "best = max(results, key=lambda k: results[k]['f1'])\n",
    "print(\"Best model by F1:\", best)\n",
    "bm = models[best]\n",
    "cm = confusion_matrix(y_val, bm.predict(X_val_sc if best in ['Logistic', 'SVM', 'KNN'] else X_val))\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 12. Voting ensemble\n",
    "# ---------------------------------------------\n",
    "vote = VotingClassifier(estimators=[(n, m) for n, m in models.items() if n in ['Logistic', 'Tree', 'Forest']], voting='soft')\n",
    "vote.fit(X_train_sc, y_train)\n",
    "vp = vote.predict(X_val_sc)\n",
    "print(\"Voting F1:\", f1_score(y_val, vp))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 13. Final submission\n",
    "# ---------------------------------------------\n",
    "bm.fit(X, y)\n",
    "vote.fit(scaler.fit_transform(X), y)\n",
    "final = vote.predict(X_test_sc)\n",
    "sub = pd.DataFrame({id_col: test_ids, target_col: final})\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "print(\"Submission written to submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
